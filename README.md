# sRRNet

Implemented a lightweight coarse-to-fine stereo matching framework optimized for embedded GPUs, 
enabling efficient and accurate depth estimation under constrained computational resources.

### input
<img src="result/sample_small.png" alt=" Image" width="35%">

### output
<img src="result/sample_large.png" alt=" Image" width="70%">

## ðŸ“¦ Requirements

Install the following packages before running the code:

```bash
pip install tensorflow-GPU==1.9.0
pip install opencv-python
pip install numpy
any other requirements
```
âš ï¸ This project was completed in September 2020, and therefore relies on older versions of some function libraries.


Also, make sure you have:

- Python 2.7+ ()
- GPU-enabled environment with CUDA/cuDNN support (for training)

## Directory Structure

```
sRRNet/
â”œâ”€â”€ config/              # JSON configuration files for training/testing
â”‚   â”œâ”€â”€ training.json
â”‚   â””â”€â”€ testing.json
â”œâ”€â”€ data/                # JSON configuration files for training/testing
â”‚   â”œâ”€â”€ train
â”‚   â”‚   â”œâ”€â”€ disp         # Quarter size of initial disparity, that obtained by [z2zncc](https://github.com/changqiong/z2zncc)
â”‚   â”‚   â”œâ”€â”€ gt
â”‚   â”‚   â”œâ”€â”€ gt_noc
â”‚   â”‚   â””â”€â”€ mini_left    # Original size of left image 
â”‚   â””â”€â”€ test
â”‚       â”œâ”€â”€ disp         # Quarter size of initial disparity, that obtained by [z2zncc](https://github.com/changqiong/z2zncc)
â”‚       â”œâ”€â”€ mini_left    # Quarter size of left image
â”‚       â””â”€â”€ test_left    # Original size of left image 
â”œâ”€â”€ model/               # Folder to save or load trained models
â”œâ”€â”€ result/              # Folder to save output images during testing
â”œâ”€â”€ main.py              # Main training/testing script
â”œâ”€â”€ tfmodel.py     	 # Model architecture
â”œâ”€â”€ data_loader.py       # Custom dataloader
â”œâ”€â”€ utils.py             # Utility functions (if any)
â””â”€â”€ README.md            # This file
```

## ðŸš€ Run

### Training

To start training, run:

```bash
python main.py --config ./config/training.json
```

This will train the model and save checkpoints in `./model/`.

### Testing

To test a model, run:

```bash
python main.py --config ./config/testing.json --model ./model/{model.name} --mode test
```

Replace `{model.name}` with your actual model file, e.g., `model-90000.meta`.

### Output

- Prediction results are saved in the `result/` folder.
- Logs and intermediate results are printed to console.



## Related Publications

> Chang, Qiong, et al. 
> "TinyStereo: A Tiny Coarse-to-Fine Framework for Vision-Based Depth Estimation on Embedded GPUs."
> IEEE Transactions on Systems, Man, and Cybernetics: Systems (2024).
---

## What to Cite

If you use this code for academic purposes, please cite the following paper:

```bibtex
@article{chang2024tinystereo,
  title={TinyStereo: A Tiny Coarse-to-Fine Framework for Vision-Based Depth Estimation on Embedded GPUs},
  author={Chang, Qiong and Xu, Xin and Zha, Aolong and Er, Meng Joo and Sun, Yongqing and Li, Yun},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  year={2024},
  publisher={IEEE}
}
```

---

## ðŸ’¡ Notes

- Code uses `tf.ConfigProto` with `allow_growth=True` to prevent full GPU memory allocation.
- The dataset must be preprocessed (e.g. by [z2zncc](https://github.com/changqiong/z2zncc))in advance and stored in the paths specified in the config file.
- The model is optimized for small-scale stereo refinement; you may adapt it for larger datasets or integrate it into existing stereo pipelines.


## License

This project is released under the [MIT License](LICENSE).

---